# GPT Model Configuration File

# Model settings
model:
  output_dir: outputs
  save_name: gpt-model-text-2-wiki.pt
  device: null  # cpu, mps or cuda. If None, will select the best available one
  model_type: GPT_CONFIG_133M  

# Training configuration
training:
  test_train_ratio: 0.75  # Test vs Train split ratio
  num_epochs: 20 # Number of epochs (1, since the dataset is already huge)
  batch_size: 12  # Suggested 8 or less for local training, 16/32/64/128 for GPU
  subset_ratio: 0.0025 # Percentage of original dataset to use (e.g., 0.1 = 10%)
  advanced_training: true  # Enables learning rate warmup, cosine decay and gradient clipping
  test_before_training: false  # If true, tests model before training (may take time)
  text_stride: 128 # While creating input/target ids, we create sliding window chunks using strides, should be less than context_length

# Inference settings
inference:
  start_context: "Water is essential for all forms of life because"
  num_beams: 1 # Set to 1 for greedy search
  max_new_tokens: 50
  temperature: 1.2
  top_k: 50
  top_p: 0.9
  early_stopping: True
  no_repeat_ngram_size: 3  
  repetition_penalty: 1.5
  do_sample: True # Used only when num_beams < 2 

# Model Architecture Configurations
model_configs: # 133M parameter configuration
  vocab_size: 50257   # Vocabulary size
  context_length: 128 # Shortened context length (orig: 1024)
  emb_dim: 768       # Embedding dimension
  n_heads: 8        # Number of attention heads
  n_layers: 8       # Number of layers
  drop_rate: 0.3    # Dropout rate
  qkv_bias: false    # Query-key-value bias
